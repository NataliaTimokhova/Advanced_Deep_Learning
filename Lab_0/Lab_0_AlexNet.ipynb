{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 0. AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the packeges\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.models as models\n",
    "from torchvision.models import AlexNet_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  0.2 Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet was originally designed and pretrained on ImageNet images, which are typically resized to 224×224. Since CIFAR-10 images are only 32×32, they need to be resized to match the expected input dimensions of AlexNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train samples: 50000 Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# Download and prepare CIFAR-10 dataset\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = CIFAR10(root='./cifar-10-batches-py', train=True, download=True, transform=transform)\n",
    "test_dataset = CIFAR10(root='./cifar-10-batches-py', train=False, download=True, transform=transform)\n",
    "\n",
    "print(\"Train samples:\", len(train_dataset), \"Test samples:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations for CIFAR-10: resize to 224 and normalize as for ImageNet\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 1: Fine‑Tuning AlexNet (All Layers Trainable)\n",
    "\n",
    "#### model_ft\n",
    "\n",
    "Fine-tuning. In this experiment, the entire pretrained AlexNet model (including the earlier layers) is updated during training on CIFAR‑10. This allows the model to adjust its weights to better suit the new task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 1/10: Loss 1.6959, Acc 37.58%\n",
      "Fine-tuning Epoch 2/10: Loss 1.2121, Acc 56.87%\n",
      "Fine-tuning Epoch 3/10: Loss 1.0359, Acc 63.54%\n",
      "Fine-tuning Epoch 4/10: Loss 0.9304, Acc 67.78%\n",
      "Fine-tuning Epoch 5/10: Loss 0.8711, Acc 69.95%\n",
      "Fine-tuning Epoch 6/10: Loss 0.8247, Acc 71.82%\n",
      "Fine-tuning Epoch 7/10: Loss 0.7741, Acc 73.67%\n",
      "Fine-tuning Epoch 8/10: Loss 0.7461, Acc 74.65%\n",
      "Fine-tuning Epoch 9/10: Loss 0.7167, Acc 75.85%\n",
      "Fine-tuning Epoch 10/10: Loss 0.7105, Acc 76.24%\n",
      "\n",
      "Test Accuracy (Fine-tuning): 75.52%\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained AlexNet and modify its classifier\n",
    "model_ft = models.alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Replace the final layer to have 10 outputs\n",
    "num_features = model_ft.classifier[6].in_features\n",
    "model_ft.classifier[6] = nn.Linear(num_features, 10)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# All parameters are trainable (fine-tuning)\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model_ft.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer_ft.zero_grad()\n",
    "        outputs = model_ft(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_ft.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100 * correct / total\n",
    "    print(f\"Fine-tuning Epoch {epoch+1}/{num_epochs}: Loss {epoch_loss:.4f}, Acc {epoch_acc:.2f}%\")\n",
    "\n",
    "# Evaluate on test set\n",
    "model_ft.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model_ft(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "test_acc_ft = 100 * correct / total\n",
    "print(f\"\\nTest Accuracy (Fine-tuning): {test_acc_ft:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 2: Feature Extraction with AlexNet (Freeze Pretrained Layers)\n",
    "\n",
    "#### model_fe\n",
    "\n",
    "Feature extraction. In this experiment, the pretrained layers of AlexNet are frozen (i.e., not updated during training), and only the new final fully connected layer (which outputs 10 classes) is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction Epoch 1/10: Loss 0.7257, Acc 74.87%\n",
      "Feature Extraction Epoch 2/10: Loss 0.6325, Acc 78.17%\n",
      "Feature Extraction Epoch 3/10: Loss 0.6081, Acc 79.01%\n",
      "Feature Extraction Epoch 4/10: Loss 0.6026, Acc 79.43%\n",
      "Feature Extraction Epoch 5/10: Loss 0.5891, Acc 79.71%\n",
      "Feature Extraction Epoch 6/10: Loss 0.5856, Acc 80.14%\n",
      "Feature Extraction Epoch 7/10: Loss 0.5852, Acc 80.26%\n",
      "Feature Extraction Epoch 8/10: Loss 0.5815, Acc 80.27%\n",
      "Feature Extraction Epoch 9/10: Loss 0.5850, Acc 80.38%\n",
      "Feature Extraction Epoch 10/10: Loss 0.5798, Acc 80.45%\n",
      "\n",
      "Test Accuracy (Feature Extraction): 81.76%\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained AlexNet\n",
    "model_fe = models.alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Freeze all the pretrained parameters\n",
    "for param in model_fe.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final layer to have 10 outputs\n",
    "num_features = model_fe.classifier[6].in_features\n",
    "model_fe.classifier[6] = nn.Linear(num_features, 10)\n",
    "# Only the new layer’s parameters will have requires_grad=True by default\n",
    "model_fe = model_fe.to(device)\n",
    "\n",
    "# Optimizer: only update the classifier's parameters\n",
    "optimizer_fe = optim.Adam(model_fe.classifier[6].parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model_fe.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer_fe.zero_grad()\n",
    "        outputs = model_fe(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_fe.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100 * correct / total\n",
    "    print(f\"Feature Extraction Epoch {epoch+1}/{num_epochs}: Loss {epoch_loss:.4f}, Acc {epoch_acc:.2f}%\")\n",
    "\n",
    "# Evaluate on test set\n",
    "model_fe.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model_fe(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "test_acc_fe = 100 * correct / total\n",
    "print(f\"\\nTest Accuracy (Feature Extraction): {test_acc_fe:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-Tuning vs. Feature Extraction:\n",
    "\n",
    "Both strategies benefit from the pretrained AlexNet features, but they adapt to the new CIFAR‑10 task in different ways:\n",
    "\n",
    "Fine‑Tuning:\n",
    "In this approach, all layers of AlexNet are updated during training. The model gradually improved from a low starting accuracy (37.6% in Epoch 1) to about 76.2% after 10 epochs. This shows that while the network can adjust its internal representations for CIFAR‑10, it may need more time or careful tuning since updating every layer increases the learning complexity.\n",
    "\n",
    "Feature Extraction:\n",
    "Here, the pretrained layers are frozen, and only the final classification layer is retrained. This approach leverages the robust, general features already learned from ImageNet without modifying them. As a result, the model starts with a higher baseline (around 74.9% in Epoch 1) and reaches about 80.5% test accuracy after 10 epochs. The quicker improvement suggests that the pretrained features are already highly relevant to CIFAR‑10, and training only the final layer simplifies the optimization task.\n",
    "\n",
    "In summary, while fine‑tuning offers more flexibility by updating the entire network, feature extraction can yield better performance in this case by efficiently leveraging the robust features learned from a large dataset like ImageNet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_labb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
